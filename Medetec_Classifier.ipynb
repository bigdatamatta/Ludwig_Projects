{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Medetec_Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulgureghian/Ludwig_Models/blob/master/Medetec_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fqQih7hWMmaK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lwomz8yNOD5M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from collections import OrderedDict\n",
        "from torch.optim import lr_scheduler \n",
        "from torchvision import  models, datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpJdybPMOgfo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/My Drive/Medetec/medetec_combined_split'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RPI0h2et6UWk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_transforms= transforms.Compose([transforms.Resize(256),\n",
        "                                         transforms.RandomRotation(45),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.RandomCrop(224),\n",
        "                                         transforms.RandomResizedCrop(224),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.485,0.456,0.406),\n",
        "                                                              (0.229,0.224,0.255))])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize((0.485,0.456,0.406),\n",
        "                                                                 (0.229,0.224,0.255))])\n",
        "\n",
        "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                         transforms.CenterCrop(224),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.485,0.456,0.406),\n",
        "                                                              (0.229,0.224,0.255))])\n",
        "\n",
        "training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
        "validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
        "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
        "\n",
        "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=32)\n",
        "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "msdlit-I_Qm9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad_(False) \n",
        "    \n",
        "model.classifier = nn.Sequential(OrderedDict([\n",
        "                                ('fc1', nn.Linear(25088, 4096)),\n",
        "                                ('relu1', nn.ReLU()),\n",
        "                                ('fc2', nn.Linear(4096, 19)), \n",
        "                                ('output', nn.Softmax(dim=1))\n",
        "                                ])) \n",
        "\n",
        "model.to(device) \n",
        "epochs = 50\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.classifier.parameters(), lr=0.01)  \n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_e2ZWlc7TKTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f180111e-3a38-4a64-cd9e-8f12dccf1bc1"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    #scheduler.step()\n",
        "    train_loss = 0\n",
        "    \n",
        "    model.train()\n",
        "    for inputs, labels in training_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model.forward(inputs)\n",
        "        \n",
        "        loss = criterion(logps, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    valid_loss = 0\n",
        "    \n",
        "    for inputs, labels in validation_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        output = model.forward(inputs)\n",
        "        \n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        valid_loss += loss.item()\n",
        "        \n",
        "        ps = torch.exp(output)\n",
        "        top_ps, top_class = ps.topk(1, dim=1) \n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        \n",
        "    print('Epoch {}/{}.. '.format(epoch+1, epochs),\n",
        "          'Training loss: {:.3f}.. '.format(train_loss / len(training_dataloader)),\n",
        "          'Validation loss: {:.3f}.. '.format(valid_loss / len(validation_dataloader)),\n",
        "          'Validation accuracy: {:.3f}.. '.format(accuracy / len(validation_dataloader)))\n",
        "          \n",
        "    model.train()      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:872: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}